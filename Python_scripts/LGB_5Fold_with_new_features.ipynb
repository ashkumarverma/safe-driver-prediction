{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from multiprocessing import *\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.42484688759\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train = pd.read_csv(\"/home/saurabhg/PuertoSergo/train.csv\")\n",
    "test = pd.read_csv(\"/home/saurabhg/PuertoSergo/test.csv\")\n",
    "print(time.time()-start)\n",
    " \n",
    "y = train['target']\n",
    "testid= test['id'].values\n",
    "\n",
    "train.drop(['id','target'],axis=1,inplace=True)\n",
    "test.drop(['id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Init Shape: ', (595212, 39))\n",
      "('After Shape: ', (595212, 41))\n",
      "('Init Shape: ', (892816, 39))\n",
      "('After Shape: ', (892816, 41))\n"
     ]
    }
   ],
   "source": [
    "### Drop calc\n",
    "unwanted = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "train = train.drop(unwanted, axis=1)  \n",
    "test = test.drop(unwanted, axis=1)\n",
    "\n",
    "### Great Recovery from Pascal's materpiece\n",
    "### Great Recovery from Pascal's materpiece\n",
    "### Great Recovery from Pascal's materpiece\n",
    "### Great Recovery from Pascal's materpiece\n",
    "### Great Recovery from Pascal's materpiece\n",
    "#train['ps_reg_03_square'] = train['ps_reg_03']*train['ps_reg_03']\n",
    "#test['ps_reg_03_square'] = test['ps_reg_03']*test['ps_reg_03']\n",
    "#train['ps_car_14_square'] = train['ps_car_14']*train['ps_car_14']\n",
    "#test['ps_car_14_square'] = test['ps_car_14']*test['ps_car_14']\n",
    "def recon(reg):\n",
    "    integer = int(np.round((40*reg)**2)) \n",
    "    for a in range(32):\n",
    "        if (integer - a) % 31 == 0:\n",
    "            A = a\n",
    "    M = (integer - A)//31\n",
    "    return A, M\n",
    "train['ps_reg_A'] = train['ps_reg_03'].apply(lambda x: recon(x)[0])\n",
    "train['ps_reg_M'] = train['ps_reg_03'].apply(lambda x: recon(x)[1])\n",
    "train['ps_reg_A'].replace(19,-1, inplace=True)\n",
    "train['ps_reg_M'].replace(51,-1, inplace=True)\n",
    "test['ps_reg_A'] = test['ps_reg_03'].apply(lambda x: recon(x)[0])\n",
    "test['ps_reg_M'] = test['ps_reg_03'].apply(lambda x: recon(x)[1])\n",
    "test['ps_reg_A'].replace(19,-1, inplace=True)\n",
    "test['ps_reg_M'].replace(51,-1, inplace=True)\n",
    "\n",
    "\n",
    "### Froza's baseline\n",
    "### Froza's baseline\n",
    "### Froza's baseline\n",
    "### Froza's baseline\n",
    "\n",
    "d_median = train.median(axis=0)\n",
    "d_mean = train.mean(axis=0)\n",
    "d_skew = train.skew(axis=0)\n",
    "one_hot = {c: list(train[c].unique()) for c in train.columns if c not in ['id','target']}\n",
    "\n",
    "def transform_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "#     for c in dcol:\n",
    "#         if '_bin' not in c: #standard arithmetic\n",
    "#             df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n",
    "#             df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n",
    "\n",
    "# #    for c in one_hot:\n",
    "#        if len(one_hot[c])>2 and len(one_hot[c]) < 7:\n",
    "#            for val in one_hot[c]:\n",
    "#                df[c+'_oh_' + str(val)] = (df[c].values == val).astype(np.int)\n",
    "    return df\n",
    "\n",
    "def multi_transform(df):\n",
    "    print('Init Shape: ', df.shape)\n",
    "    p = Pool(cpu_count())\n",
    "    df = p.map(transform_df, np.array_split(df, cpu_count()))\n",
    "    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "    p.close(); p.join()\n",
    "    print('After Shape: ', df.shape)\n",
    "    return df\n",
    "\n",
    "train = multi_transform(train)\n",
    "test = multi_transform(test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute gini\n",
    "\n",
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "\n",
    "@jit\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    "\n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_lgb(act, preds):\n",
    "#    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(act, preds)\n",
    "    return 'gini', gini_score,True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 5000\n",
    "OPTIMIZE_ROUNDS = True\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50  \n",
    "f_cats = [f for f in train.columns if \"_cat\" in f]\n",
    "# Note: I set EARLY_STOPPING_ROUNDS high so that (when OPTIMIZE_ROUNDS is set)\n",
    "#       I will get lots of information to make my own judgment.  You should probably\n",
    "#       reduce EARLY_STOPPING_ROUNDS if you want to do actual early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "n_estimators = 1000\n",
    "folds = KFold(n_splits=n_splits, shuffle=True, random_state=1) \n",
    "imp_df = np.zeros((len(train.columns), n_splits))\n",
    "oof = np.empty(len(train))\n",
    "sub_preds = np.zeros((len(test),n_splits))\n",
    "increase = False\n",
    "np.random.seed(0)\n",
    "params = {'eta': 0.025, 'max_depth': 4, \n",
    "          'subsample': 0.9, 'colsample_bytree': 0.7, \n",
    "          'colsample_bylevel':0.7,\n",
    "          'min_child_weight':100,\n",
    "          'alpha':10,\n",
    "          'objective': 'binary:logistic', 'eval_metric': 'auc', 'seed': 99, 'silent': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[100]\ttraining's gini: 0.26205\tvalid_1's gini: 0.248071\n",
      "[200]\ttraining's gini: 0.289259\tvalid_1's gini: 0.269466\n",
      "[300]\ttraining's gini: 0.308346\tvalid_1's gini: 0.280823\n",
      "[400]\ttraining's gini: 0.321581\tvalid_1's gini: 0.285163\n",
      "[500]\ttraining's gini: 0.331958\tvalid_1's gini: 0.286578\n",
      "[600]\ttraining's gini: 0.340581\tvalid_1's gini: 0.286885\n",
      "Early stopping, best iteration is:\n",
      "[571]\ttraining's gini: 0.338262\tvalid_1's gini: 0.287022\n",
      "Fold  1 : 0.286978 @1000 / best score is 621.000000 @ 570\n",
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[100]\ttraining's gini: 0.262582\tvalid_1's gini: 0.251428\n",
      "[200]\ttraining's gini: 0.290713\tvalid_1's gini: 0.267447\n",
      "[300]\ttraining's gini: 0.30948\tvalid_1's gini: 0.276033\n",
      "[400]\ttraining's gini: 0.322323\tvalid_1's gini: 0.28001\n",
      "[500]\ttraining's gini: 0.332776\tvalid_1's gini: 0.281527\n",
      "[600]\ttraining's gini: 0.342014\tvalid_1's gini: 0.281945\n",
      "Early stopping, best iteration is:\n",
      "[579]\ttraining's gini: 0.340061\tvalid_1's gini: 0.2822\n",
      "Fold  2 : 0.282180 @1000 / best score is 629.000000 @ 578\n",
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[100]\ttraining's gini: 0.265057\tvalid_1's gini: 0.240251\n",
      "[200]\ttraining's gini: 0.293925\tvalid_1's gini: 0.259516\n",
      "[300]\ttraining's gini: 0.312906\tvalid_1's gini: 0.269418\n",
      "[400]\ttraining's gini: 0.326071\tvalid_1's gini: 0.272797\n",
      "[500]\ttraining's gini: 0.336311\tvalid_1's gini: 0.273886\n",
      "[600]\ttraining's gini: 0.345465\tvalid_1's gini: 0.274834\n",
      "Early stopping, best iteration is:\n",
      "[622]\ttraining's gini: 0.347315\tvalid_1's gini: 0.275159\n",
      "Fold  3 : 0.275141 @1000 / best score is 672.000000 @ 621\n",
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[100]\ttraining's gini: 0.258099\tvalid_1's gini: 0.26552\n",
      "[200]\ttraining's gini: 0.286422\tvalid_1's gini: 0.28522\n",
      "[300]\ttraining's gini: 0.305769\tvalid_1's gini: 0.294213\n",
      "[400]\ttraining's gini: 0.31911\tvalid_1's gini: 0.297411\n",
      "Early stopping, best iteration is:\n",
      "[449]\ttraining's gini: 0.324335\tvalid_1's gini: 0.298483\n",
      "Fold  4 : 0.298458 @1000 / best score is 499.000000 @ 448\n",
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[100]\ttraining's gini: 0.263918\tvalid_1's gini: 0.245092\n",
      "[200]\ttraining's gini: 0.290872\tvalid_1's gini: 0.264896\n",
      "[300]\ttraining's gini: 0.309223\tvalid_1's gini: 0.275171\n",
      "[400]\ttraining's gini: 0.322351\tvalid_1's gini: 0.281449\n",
      "[500]\ttraining's gini: 0.332365\tvalid_1's gini: 0.284519\n",
      "[600]\ttraining's gini: 0.341379\tvalid_1's gini: 0.285963\n",
      "[700]\ttraining's gini: 0.349677\tvalid_1's gini: 0.287086\n",
      "Early stopping, best iteration is:\n",
      "[746]\ttraining's gini: 0.353178\tvalid_1's gini: 0.287459\n",
      "Fold  5 : 0.287415 @1000 / best score is 796.000000 @ 745\n",
      "Full OOF score : 0.285716\n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(y, y)):\n",
    "    trn_dat, trn_tgt = train.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_dat, val_tgt = train.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    clf = lgb.LGBMModel(n_estimators=n_estimators,\n",
    "                        num_leaves=16,\n",
    "   #                     boosting_type = 'dart',\n",
    "                        objective=\"binary\",\n",
    "                        learning_rate=.025, \n",
    "                        subsample=.9, \n",
    "                        colsample_bytree=.7,\n",
    "         #               min_split_gain = .77,\n",
    "        #                min_child_samples= 500,\n",
    "         #               is_unbalance = True,\n",
    "                        min_child_weight =100,\n",
    "                        reg_alpha=4,\n",
    "          #              reg_lambda=2,\n",
    "                      #  nthread=2\n",
    "                       )\n",
    "    # Upsample during cross validation to avoid having the same samples\n",
    "    # in both train and validation sets\n",
    "    # Validation set is not up-sampled to monitor overfitting\n",
    "    if increase:\n",
    "        # Get positive examples\n",
    "        pos = pd.Series(trn_tgt == 1)\n",
    "        # Add positive examples\n",
    "        trn_dat = pd.concat([trn_dat, trn_dat.loc[pos]], axis=0)\n",
    "        trn_tgt = pd.concat([trn_tgt, trn_tgt.loc[pos]], axis=0)\n",
    "        # Shuffle data\n",
    "        idx = np.arange(len(trn_dat))\n",
    "        np.random.shuffle(idx)\n",
    "        trn_dat = trn_dat.iloc[idx]\n",
    "        trn_tgt = trn_tgt.iloc[idx]\n",
    "        \n",
    "    clf.fit(trn_dat, trn_tgt, \n",
    "            eval_set=[(trn_dat, trn_tgt), (val_dat, val_tgt)],\n",
    "            categorical_feature = f_cats,\n",
    "            eval_metric=gini_lgb,\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=100)\n",
    "    # Find best round for validation setA\n",
    "    lgb_evals = clf.evals_result_[\"valid_1\"][\"gini\"]\n",
    "    #print(clf.evals_result_ )\n",
    "    # Keep feature importances\n",
    "    imp_df[:, fold_] = clf.feature_importances_\n",
    "    #Xgboost provides best round starting from 0 so it has to be incremented\n",
    "    best_round = np.argsort(lgb_evals)[::-1][0]\n",
    "\n",
    "    # Predict OOF and submission probas with the best round\n",
    "    oof[val_idx] = clf.predict(val_dat, num_iteration=best_round)\n",
    "    # Update submission\n",
    "    sub_preds[:, fold_] = clf.predict(test, num_iteration=best_round)\n",
    "\n",
    "    # Display results\n",
    "    print(\"Fold %2d : %.6f @%4d / best score is %.6f @%4d\"\n",
    "          % (fold_ + 1,\n",
    "             gini_normalized(val_tgt, oof[val_idx]),\n",
    "             n_estimators,\n",
    "             len(lgb_evals),\n",
    "             best_round))\n",
    "          \n",
    "print(\"Full OOF score : %.6f\" % gini_normalized(y, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_pred= np.delete(sub_preds,2,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_03                          :     0.0792\n",
      "ps_car_13                          :     0.0765\n",
      "ps_car_13_x_ps_reg_03              :     0.0657\n",
      "ps_ind_15                          :     0.0578\n",
      "ps_ind_01                          :     0.0527\n",
      "ps_ind_05_cat                      :     0.0501\n",
      "ps_reg_02                          :     0.0485\n",
      "ps_reg_01                          :     0.0433\n",
      "ps_car_14                          :     0.0407\n",
      "ps_car_01_cat                      :     0.0390\n",
      "ps_ind_17_bin                      :     0.0342\n",
      "ps_reg_03                          :     0.0340\n",
      "ps_car_11_cat                      :     0.0336\n",
      "ps_car_15                          :     0.0311\n",
      "ps_reg_A                           :     0.0270\n",
      "ps_car_09_cat                      :     0.0256\n",
      "ps_car_06_cat                      :     0.0250\n",
      "ps_reg_M                           :     0.0240\n",
      "ps_car_07_cat                      :     0.0228\n",
      "ps_car_04_cat                      :     0.0195\n",
      "ps_ind_02_cat                      :     0.0191\n",
      "ps_car_03_cat                      :     0.0184\n",
      "ps_car_12                          :     0.0168\n",
      "ps_ind_07_bin                      :     0.0162\n",
      "ps_car_11                          :     0.0158\n",
      "ps_ind_04_cat                      :     0.0132\n",
      "ps_ind_16_bin                      :     0.0119\n",
      "ps_ind_06_bin                      :     0.0115\n",
      "ps_ind_09_bin                      :     0.0098\n",
      "ps_car_05_cat                      :     0.0095\n",
      "negative_one_vals                  :     0.0095\n",
      "ps_ind_08_bin                      :     0.0075\n",
      "ps_car_02_cat                      :     0.0040\n",
      "ps_car_08_cat                      :     0.0037\n",
      "ps_ind_18_bin                      :     0.0021\n",
      "ps_ind_14                          :     0.0007\n",
      "ps_ind_12_bin                      :     0.0001\n",
      "ps_car_10_cat                      :     0.0001\n",
      "ps_ind_13_bin                      :     0.0000\n",
      "ps_ind_11_bin                      :     0.0000\n",
      "ps_ind_10_bin                      :     0.0000\n"
     ]
    }
   ],
   "source": [
    "importances = sorted([(train.columns[i], imp) for i, imp in enumerate(imp_df.mean(axis=1))],\n",
    "                     key=lambda x: x[1])\n",
    "\n",
    "for f, imp in importances[::-1]:\n",
    "    print(\"%-34s : %10.4f\" % (f, imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = testid\n",
    "sub[\"target\"] =scipy.stats.hmean(sub_pred,axis=1)\n",
    "sub.to_csv(\"submission_10312017_LGB_.0.285716_5kfold_4pred.csv\", index=False, float_format=\"%.9f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
