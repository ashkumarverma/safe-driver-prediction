{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puneetj/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import lightgbm as lgb\n",
    "import scipy\n",
    "from multiprocessing import *\n",
    "from Utils.Custom_loss_functions import gini_normalized,gini_lgb,gini\n",
    "from Data_Prep.data_prep import *\n",
    "from Models.lgb_model import *\n",
    "from Utils.Log_Driver import get_log,reinitiate_logfile\n",
    "import traceback\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import exp, log\n",
    "import xgboost as xgb\n",
    "import data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        tmin, tsec = divmod((datetime.now() - start_time).total_seconds(), 60)\n",
    "        logger.info(' Time taken: %i minutes and %s seconds.' %\n",
    "              (tmin, round(tsec, 2)))\n",
    "\n",
    "\n",
    "def scale_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Load_data():\n",
    "    time = timer()\n",
    "    train = pd.read_csv(\"/home/saurabhg/PuertoSergo/train.csv\")\n",
    "    timer(time)\n",
    "    test = pd.read_csv(\"/home/saurabhg/PuertoSergo/test.csv\")\n",
    "    timer(time)\n",
    "    y = train[\"target\"]\n",
    "    testid= test['id'].values\n",
    "    trainid = train[\"id\"].values\n",
    "    train.drop(['id','target'],axis=1,inplace=True)\n",
    "    test.drop(['id'],axis=1,inplace=True)\n",
    "    return train,test,y,testid,trainid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_data(train, test,y,rm_calc_Cols = True,reconfig_ps_reg =True,one_hot = True,target_encoding = False):\n",
    "    time = timer()\n",
    "    f_cats = [f for f in train.columns if \"_cat\" in f]\n",
    "    if rm_calc_Cols:\n",
    "        unwanted = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "        train = train.drop(unwanted, axis=1)  \n",
    "        test = test.drop(unwanted, axis=1)\n",
    "        timer(time)\n",
    "        logger.info(\"calc fields dropped\")\n",
    "    if reconfig_ps_reg:\n",
    "        train['ps_reg_A'] = train['ps_reg_03'].apply(lambda x: recon(x)[0])\n",
    "        train['ps_reg_M'] = train['ps_reg_03'].apply(lambda x: recon(x)[1])\n",
    "        train['ps_reg_A'].replace(19,-1, inplace=True)\n",
    "        train['ps_reg_M'].replace(51,-1, inplace=True)\n",
    "        test['ps_reg_A'] = test['ps_reg_03'].apply(lambda x: recon(x)[0])\n",
    "        test['ps_reg_M'] = test['ps_reg_03'].apply(lambda x: recon(x)[1])\n",
    "        test['ps_reg_A'].replace(19,-1, inplace=True)\n",
    "        test['ps_reg_M'].replace(51,-1, inplace=True)\n",
    "        timer(time)\n",
    "        logger.info(\"Reconfigured PS Reg 03\")\n",
    "    if one_hot:\n",
    "        d_median = train.median(axis=0)\n",
    "        d_mean = train.mean(axis=0)\n",
    "        d_skew = train.skew(axis=0)\n",
    "        one_hot = {c: list(train[c].unique()) for c in train.columns if c not in ['id','target']}\n",
    "        \n",
    "        train = multi_transform(train,d_median,d_mean,one_hot)\n",
    "        test = multi_transform(test,d_median,d_mean,one_hot)\n",
    "        timer(time)\n",
    "        logger.info(\"One hot encoded variables\")\n",
    "        \n",
    "    if target_encoding:\n",
    "        for f in f_cats:\n",
    "            train[f + \"_avg\"],test[f + \"_avg\"] = target_encode(trn_series=train[f],\n",
    "                                                                tst_series=test[f],\n",
    "                                                                target=y,\n",
    "                                                                min_samples_leaf=200,\n",
    "                                                                smoothing=10,\n",
    "                                                                noise_level=0)\n",
    "        timer(time)\n",
    "        logger.info(\"Target Encoding of categorical variables\")\n",
    "    return train,test     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#logger =reinitiate_logfile(logger,\"First_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class KFold_ensemble():    \n",
    "    def __init__(self,train= None,y=None,test= 1,trainid= None,testid = None,\n",
    "                 n_splits =2,shuffle= True,random_state = 15,params = None,\n",
    "                 stratify = True,classifier= \"LGB\",Cat_features = None):\n",
    "        self.n_splits = n_splits\n",
    "        self.testid = testid\n",
    "        self.trainid = trainid\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        self.classifier = classifier\n",
    "        self.params = params\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.Cat_features = Cat_features\n",
    "        self.stratify=stratify\n",
    "        self.y=y\n",
    "        self.folds = self.Stratified_flag()\n",
    "        self.model_param = self.Makemodel()\n",
    "        #self.sub_preds = np.zeros(len(sub_df))\n",
    "        \n",
    "    def Modelselect(self):\n",
    "            return (lightgbm().build_from_json(self.params)).lgb_params()\n",
    "        \n",
    "        \n",
    "    def get_kfold_parameters(self,clf):\n",
    "        if self.n_splits>1:\n",
    "            self.imp_df = np.zeros((len(self.train.columns), self.n_splits))\n",
    "            self.evals = np.zeros((clf.n_estimators, self.n_splits))\n",
    "            self.oof = np.empty(len(train))\n",
    "            \n",
    "    \n",
    "    def Stratified_flag(self):\n",
    "        if self.stratify == True:\n",
    "            return StratifiedKFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state ) \n",
    "        else:\n",
    "            return KFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state ) \n",
    "        \n",
    "    def test_available(self):\n",
    "        if not self.test.empty:\n",
    "            self.sub_preds = np.zeros((len(self.test),self.n_splits))\n",
    "            print(1)\n",
    "        else:\n",
    "            self.sub_preds =None\n",
    "            \n",
    "    def Makemodel(self):\n",
    "        for fold_, (trn_idx, val_idx) in enumerate(self.folds.split(self.y, self.y)):\n",
    "            trn_dat, trn_tgt = self.train.iloc[trn_idx], self.y.iloc[trn_idx]\n",
    "            val_dat, val_tgt = self.train.iloc[val_idx], self.y.iloc[val_idx]\n",
    "            logger.info (fold_)\n",
    "            if self.classifier==\"LGB\":\n",
    "                clf=(lightgbm().build_from_json(self.params)).lgb_params()\n",
    "                train_params  = lgb_train().build_from_json(self.params)\n",
    "                if train_params.eval_set:\n",
    "                    train_params.set_eval_set(trn_dat,trn_tgt,val_dat,val_tgt)\n",
    "                    if self.Cat_features:\n",
    "                        train_params.Cat_features(Cat_features) \n",
    "                clf = train_params.fit(clf,trn_dat,trn_tgt)\n",
    "                if fold_==0:\n",
    "                    self.get_kfold_parameters(clf)\n",
    "                    self.test_available()\n",
    "                # Find best round for validation setA\n",
    "                self.evals[:, fold_] = clf.evals_result_[\"valid_1\"][clf.evals_result_[\"valid_1\"].keys()[0]]\n",
    "                # Keep feature importances\n",
    "                self.imp_df[:, fold_] = clf.feature_importances_\n",
    "                # Predict OOF and submission probas with the best round\n",
    "                best_round = np.argsort(self.evals[:, fold_])[::-1][0]\n",
    "                 # Update submission\n",
    "                self.oof[val_idx] = clf.predict(val_dat, num_iteration=best_round)\n",
    "                if not self.test.empty:\n",
    "                    self.sub_preds[:, fold_] = clf.predict(self.test, num_iteration=best_round)\n",
    "#                 logger.info(\"Fold %2d : %.6f @%4d / best score is %.6f @%4d\"\n",
    "#                                                             % (fold_ + 1,\n",
    "#                                                             gini_normalized(val_tgt, self.oof[val_idx]),\n",
    "#                                                             clf.n_estimators,\n",
    "#                                                             len(self.evals),\n",
    "#                                                             best_round))\n",
    "    def variable_importance(self):\n",
    "        importances = sorted([(self.train.columns[i], imp) for i, imp in enumerate(self.imp_df.mean(axis=1))],\n",
    "                            key=lambda x: x[1])\n",
    "        logger.info(\"printing variable importance......\")\n",
    "        for f, imp in importances[::-1]:\n",
    "            logger.info(\"%-34s : %10.4f\" % (f, imp))\n",
    "                \n",
    "    def submission_file(self,name = \"Testsubmission\"):\n",
    "        sub = pd.DataFrame()\n",
    "        sub['id'] = self.testid\n",
    "        print self.oof\n",
    "        sub[\"target\"] = scipy.stats.hmean(self.sub_preds,axis=1)\n",
    "        sub.to_csv(name+\".csv\", index=False, float_format=\"%.9f\")\n",
    "        logger.info(\"CSV written to %s ......\"%name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params  ={\n",
    "    \"tuning_parameters\":{\n",
    "        \"n_estimators\" : 100\n",
    "    },\n",
    "    \"train_parameters\":{\n",
    "        \"eval_set\" : True,\n",
    "        \"early_stopping_rounds\" :25,\n",
    "        \"verbose\":20,\n",
    "        \"eval_metric\" : gini_lgb\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__info__: Time taken: 0 minutes and 3.78 seconds.\n",
      "INFO:__info__: Time taken: 0 minutes and 9.28 seconds.\n",
      "INFO:__info__: Time taken: 0 minutes and 0.16 seconds.\n",
      "INFO:__info__:calc fields dropped\n",
      "INFO:__info__: Time taken: 0 minutes and 4.47 seconds.\n",
      "INFO:__info__:Target Encoding of categorical variables\n",
      "INFO:__info__:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Train until valid scores didn't improve in 25 rounds.\n",
      "[20]\tvalid_0's gini_lgb: 0.267908\tvalid_1's gini_lgb: 0.237953\n",
      "[40]\tvalid_0's gini_lgb: 0.273105\tvalid_1's gini_lgb: 0.241591\n",
      "[60]\tvalid_0's gini_lgb: 0.277401\tvalid_1's gini_lgb: 0.244207\n",
      "[80]\tvalid_0's gini_lgb: 0.278675\tvalid_1's gini_lgb: 0.245414\n",
      "[100]\tvalid_0's gini_lgb: 0.279425\tvalid_1's gini_lgb: 0.246362"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__info__:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n",
      "Train until valid scores didn't improve in 25 rounds.\n",
      "[20]\tvalid_0's gini_lgb: 0.269243\tvalid_1's gini_lgb: 0.244828\n",
      "[40]\tvalid_0's gini_lgb: 0.274557\tvalid_1's gini_lgb: 0.248061\n",
      "[60]\tvalid_0's gini_lgb: 0.279064\tvalid_1's gini_lgb: 0.251659\n",
      "[80]\tvalid_0's gini_lgb: 0.280586\tvalid_1's gini_lgb: 0.252492\n",
      "[100]\tvalid_0's gini_lgb: 0.282923\tvalid_1's gini_lgb: 0.254003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__info__:printing variable importance......\n",
      "INFO:__info__:ps_car_13                          :     0.0965\n",
      "INFO:__info__:ps_reg_03                          :     0.0959\n",
      "INFO:__info__:ps_ind_17_bin                      :     0.0654\n",
      "INFO:__info__:ps_ind_03                          :     0.0575\n",
      "INFO:__info__:ps_car_11_cat_avg                  :     0.0544\n",
      "INFO:__info__:ps_ind_05_cat_avg                  :     0.0526\n",
      "INFO:__info__:ps_reg_02                          :     0.0519\n",
      "INFO:__info__:ps_ind_15                          :     0.0491\n",
      "INFO:__info__:ps_ind_05_cat                      :     0.0365\n",
      "INFO:__info__:ps_car_01_cat_avg                  :     0.0356\n",
      "INFO:__info__:ps_reg_01                          :     0.0346\n",
      "INFO:__info__:ps_ind_01                          :     0.0312\n",
      "INFO:__info__:ps_car_14                          :     0.0243\n",
      "INFO:__info__:ps_ind_07_bin                      :     0.0240\n",
      "INFO:__info__:ps_car_07_cat                      :     0.0234\n",
      "INFO:__info__:ps_car_01_cat                      :     0.0234\n",
      "INFO:__info__:ps_car_03_cat                      :     0.0218\n",
      "INFO:__info__:ps_car_06_cat                      :     0.0199\n",
      "INFO:__info__:ps_ind_16_bin                      :     0.0197\n",
      "INFO:__info__:ps_car_09_cat                      :     0.0193\n",
      "INFO:__info__:ps_car_09_cat_avg                  :     0.0168\n",
      "INFO:__info__:ps_car_12                          :     0.0160\n",
      "INFO:__info__:ps_ind_06_bin                      :     0.0160\n",
      "INFO:__info__:ps_car_11_cat                      :     0.0143\n",
      "INFO:__info__:ps_car_06_cat_avg                  :     0.0119\n",
      "INFO:__info__:ps_car_04_cat                      :     0.0106\n",
      "INFO:__info__:ps_car_15                          :     0.0099\n",
      "INFO:__info__:ps_car_11                          :     0.0078\n",
      "INFO:__info__:ps_ind_04_cat                      :     0.0078\n",
      "INFO:__info__:ps_car_07_cat_avg                  :     0.0071\n",
      "INFO:__info__:ps_car_05_cat                      :     0.0068\n",
      "INFO:__info__:ps_ind_02_cat                      :     0.0062\n",
      "INFO:__info__:ps_ind_02_cat_avg                  :     0.0054\n",
      "INFO:__info__:ps_car_03_cat_avg                  :     0.0050\n",
      "INFO:__info__:ps_ind_08_bin                      :     0.0041\n",
      "INFO:__info__:ps_ind_09_bin                      :     0.0041\n",
      "INFO:__info__:ps_car_02_cat                      :     0.0021\n",
      "INFO:__info__:ps_car_08_cat                      :     0.0018\n",
      "INFO:__info__:ps_car_04_cat_avg                  :     0.0018\n",
      "INFO:__info__:ps_car_05_cat_avg                  :     0.0016\n",
      "INFO:__info__:ps_car_10_cat                      :     0.0015\n",
      "INFO:__info__:ps_ind_14                          :     0.0015\n",
      "INFO:__info__:ps_ind_04_cat_avg                  :     0.0010\n",
      "INFO:__info__:ps_ind_18_bin                      :     0.0010\n",
      "INFO:__info__:ps_car_10_cat_avg                  :     0.0006\n",
      "INFO:__info__:ps_car_08_cat_avg                  :     0.0003\n",
      "INFO:__info__:ps_car_02_cat_avg                  :     0.0001\n",
      "INFO:__info__:ps_ind_13_bin                      :     0.0001\n",
      "INFO:__info__:ps_ind_12_bin                      :     0.0001\n",
      "INFO:__info__:ps_ind_11_bin                      :     0.0000\n",
      "INFO:__info__:ps_ind_10_bin                      :     0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 0.21873235  0.20278264  0.20244026 ...,  0.20352998  0.20773393\n",
      "  0.20672752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__info__:CSV written to dummy ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    logger = get_log(\"First_log\")\n",
    "    train,test,y,testid,trainid = Load_data()\n",
    "    f_cats = [f for f in train.columns if \"_cat\" in f]\n",
    "    train,test = prep_data(train,test,y,\n",
    "                           rm_calc_Cols= True,\n",
    "                           reconfig_ps_reg =False,\n",
    "                           one_hot = False,\n",
    "                           target_encoding =True )\n",
    "    lgb_ensemble = KFold_ensemble(train,y,test,trainid=trainid,testid=testid,params=params)\n",
    "    lgb_ensemble.variable_importance()\n",
    "    lgb_ensemble.submission_file(\"dummy\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20016314,  0.20223653,  0.20535973, ...,  0.20963646,\n",
       "        0.2055928 ,  0.2038792 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_ensemble.sub_preds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.empty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
